---
title: "Practical_maximum_likelihood_estimation_ Oscar_Contreras_Rafael_Castilla"
author: "F.R.Castilla, O.Contreras"
date: "2022-10-03"
output: 
  pdf_document:
      latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

## R Markdown

Resolve the following exercise in groups of two students. Write your solution in a Word, Latex or Markdown document and generate a pdf file with your solution. 
Upload the pdf file with your solution to the corresponding task at the Moodle environment of the course, no later than the hand-in date.

1.(16p) ML estimation of a one-parameter distribution. 
  Let X be a random variable with probability density
$f(x|\beta)=\beta x^{b-1}$ with $\geq x\geq1$, $\beta >0$
 we consider a random sample of n observation of this distribution.
 
 a) (2p) Write down the likelihood function for a sample of n observations of this distribution.
 <div style="background-color:#F0F0F0">
&emsp;<i class="fas fa-comment-dots"></i>
Answer: $L(\beta|x)=\prod_{i=1}^{n} f(x_i|\beta) =\prod_{i=1}^{n} \beta x^{b-1}_{i}=\beta^{n}\prod_{i=1}^{n}x_i^{b-1}$ 
&emsp;
</div>
```{r}
likeli<-function(b,x){
  n<-row(x)
  l<-b^n*prod(x^(b-1))  
  return(l)
}
```
b) (1p) Obtain the log-likelihood function
$log(L(\beta|x_i) = nlog(\beta)+\sum^n_{i=1}(\beta-1)log(x_i)=nlog(\beta)+n(\beta-1)\sum^{n}_{i-1}log(x_i)$
```{r}
loglike<-function(b,x){
n<-nrow(x)
l<-n*log(b)+(n*(b-1))*sum(log(x))
return(l)
}


```

c) (2p) Find the stationary point(s) of the log-likelihood function analytically.
$\frac{dlog(L(\beta|x))}{d\beta}=\frac{n}{\beta}+n\sum^n_{i=1}x_i$
for find the stationary poitt the derivate qual to 0
$0=\frac{n}{\beta}+n\sum^n_{i=1}x_i$\\
$\beta=\frac{1}{sum^n_{i=1}log(x_i)}$


d)(1p) Determine whether the stationary point(s) are maxima or minima.

for know if the stationary point is maxima or minima the need the 2 derivate
$\frac{d^2l}{d^2\beta}=-\frac{n}{\beta^2}$
and if the result is positive is the minimum and if is negative is a maximum

e) 1p) Download the file Sample.dat, which contains sample of obser-
vations from this probability distribution. Determine the sample size
and calculate the value of the ML estimator for this sample.

```{r}
x<-read.table('~/Statistic/Sample.dat')
print(paste0("the sample size is: ", nrow(x)))
#if use the derivate of loglikelihood
ml<--1/sum(log(x))
print(paste0("the ML estimator is: ",ml))

```

f) 2p) Plot the log-likelihood function, and assess graphically if your ML estimate coincides with the maximum of this function.

```{r}
library(ggplot2)
b<-seq(0.0,0.02,by=0.001)
d<-data.frame("predictor"=b,"loglike"=loglike(b,x))
ggplot(d,aes(y=loglike,x=predictor))+
  geom_point()+geom_point(aes(ml,loglike(ml,x)),colour="red")

```
the maximum correspond with the graph
          
g) (1p) Determine an expression for the Fisher information by calculating
$-E(\frac{d^2l}{d\beta^2})$
$-E(\frac{n}{\beta^2})$


